{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4442ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code that tunes and trains the ARIMA model on all the exchange rates to perform forecasts and calculate the model uncertainty using the ARIMA model itself.\n",
    "# Author Samwel Portelli <samwel.portelli.18@um.edu.mt>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a978d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deel.puncc.metrics import regression_ace\n",
    "from deel.puncc.metrics import regression_mean_coverage\n",
    "from deel.puncc.metrics import regression_sharpness\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pmdarima\n",
    "from pmdarima.arima import ndiffs\n",
    "import pmdarima as pm\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def direction_accuracy(actual, predicted):\n",
    "    \"\"\"\n",
    "    Calculate the direction accuracy between actual and predicted values.\n",
    "\n",
    "    Parameters:\n",
    "    actual (list): List of actual values (time series).\n",
    "    predicted (list): List of predicted values (time series).\n",
    "\n",
    "    Returns:\n",
    "    float: Direction accuracy in percentage.\n",
    "    \"\"\"\n",
    "    # Ensure the lengths of actual and predicted are the same\n",
    "    if len(actual) != len(predicted):\n",
    "        raise ValueError(\"Input lists must have the same length.\")\n",
    "\n",
    "    # Calculate differences between consecutive values\n",
    "    actual_diff = [actual[i] - actual[i-1] for i in range(1, len(actual))]\n",
    "    predicted_diff = [predicted[i] - actual[i-1] for i in range(1, len(predicted))]\n",
    "\n",
    "    # Count the number of correct predictions\n",
    "    correct_predictions = sum((a * p) > 0 for a, p in zip(actual_diff, predicted_diff))\n",
    "\n",
    "    # Calculate accuracy as a percentage\n",
    "    accuracy_percentage = (correct_predictions / len(actual_diff)) * 100.0\n",
    "\n",
    "    return float(accuracy_percentage)\n",
    "\n",
    "def create_unique_folder(folder_name):\n",
    "    version = 1\n",
    "    new_folder_name = folder_name\n",
    "    while os.path.exists(new_folder_name):\n",
    "        new_folder_name = f\"{folder_name}_v{version}\"\n",
    "        version += 1\n",
    "    os.makedirs(new_folder_name)\n",
    "    return new_folder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3693f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_one_step(model, exog_y_test_values, alpha):\n",
    "    fc, conf_int = model.predict(n_periods=1,X=exog_y_test_values, return_conf_int=True, alpha=alpha)\n",
    "    return (\n",
    "        fc.tolist()[0],\n",
    "        np.asarray(conf_int).tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24592970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the exchange_rate dataset\n",
    "data = pd.read_csv(\"C:/Users/porte/Downloads/dataset/exchange_rate/exchange_rate.csv\", index_col='date', parse_dates=True)\n",
    "\n",
    "# Select the relevant columns for the model\n",
    "columns = ['0', '1', '2', '3', '4', '5', '6', 'OT']\n",
    "\n",
    "# Extract the relevant subset for training and testing\n",
    "window_size = 20\n",
    "\n",
    "train_data = data.iloc[:5311]\n",
    "test_data = data.iloc[5291:]\n",
    "\n",
    "train_end = 5311\n",
    "test_start = 5311\n",
    "test_end = len(data)\n",
    "\n",
    "alphas=[0.01, 0.05, 0.1, 0.15]\n",
    "confidence=np.subtract(np.ones(len(alphas)), alphas)\n",
    "\n",
    "targets = ['0', '1', '2', '3', '4', '5', '6', 'OT']\n",
    "\n",
    "folder_names = ['.\\\\arimarunningaModelPerAlpha\\\\test_arima_model_data_0', '.\\\\arimarunningaModelPerAlpha\\\\test_arima_model_data_1', '.\\\\arimarunningaModelPerAlpha\\\\test_arima_model_data_2', '.\\\\arimarunningaModelPerAlpha\\\\test_arima_model_data_3', '.\\\\arimarunningaModelPerAlpha\\\\test_arima_model_data_4', '.\\\\arimarunningaModelPerAlpha\\\\test_arima_model_data_5', '.\\\\arimarunningaModelPerAlpha\\\\test_arima_model_data_6', '.\\\\arimarunningaModelPerAlpha\\\\test_arima_model_data_OT']\n",
    "\n",
    "orders = []\n",
    "model_alpha = []\n",
    "\n",
    "for ind, target in enumerate(targets):\n",
    "     \n",
    "    folder_name = create_unique_folder(folder_names[ind])\n",
    "        \n",
    "    # Create rolling windows for training data\n",
    "    train_X, train_y = create_rolling_windows(train_data, window_size, target)\n",
    "\n",
    "    # Create rolling windows for testing data\n",
    "    test_X, test_y = create_rolling_windows(test_data, window_size, target)\n",
    "\n",
    "    ace_list, mean_coverage_list, average_width_list, direction_accuracy_value_list = [], [], [], []\n",
    "\n",
    "    for alpha in alphas:\n",
    "        \n",
    "        df = pd.read_csv(\"C:/Users/porte/Downloads/dataset/exchange_rate/exchange_rate.csv\", usecols=[target], parse_dates=True)\n",
    "        df.rename(columns={target: \"Open\"}, inplace=True)\n",
    "\n",
    "        exog_var = targets.remove(target)\n",
    "\n",
    "        exog_df = pd.read_csv(\"C:/Users/porte/Downloads/dataset/exchange_rate/exchange_rate.csv\", usecols=exog_var, parse_dates=False)\n",
    "        exog_df = exog_df.drop(['date'], axis=1)\n",
    "\n",
    "        y_train = df[1:train_end].values\n",
    "        y_test = df[test_start:test_end].values\n",
    "\n",
    "        exog_y_train = exog_df[:train_end-1].values\n",
    "        exog_y_test = exog_df[test_start:test_end].values\n",
    "        exog_y_test = np.concatenate((np.array([exog_y_train[-1]]), exog_y_test[:-1]))\n",
    "\n",
    "        kpss_diffs = ndiffs(y_train, alpha=0.05, test='kpss', max_d=6)\n",
    "        adf_diffs = ndiffs(y_train, alpha=0.05, test='adf', max_d=6)\n",
    "        n_diffs = max(adf_diffs, kpss_diffs)\n",
    "        \n",
    "        model = pm.auto_arima(y_train, exog_y_train, d=n_diffs, seasonal=False, stepwise=True,\n",
    "                         suppress_warnings=True, max_p=6, trace=2)\n",
    "\n",
    "        print(model.order)\n",
    "        orders.append(model.order)\n",
    "        model_alpha.append(str(target)+'_'+str(alpha))\n",
    "\n",
    "        print('Testing alpha value: '+str(alpha))\n",
    "\n",
    "        # Generate forecasts\n",
    "        forecast_values, forecast_intervals_lower, forecast_intervals_upper = [], [], []\n",
    "        \n",
    "        for ind, new_ob in enumerate(y_test):\n",
    "            \n",
    "            fc, conf = forecast_one_step(model, np.array([exog_y_test[ind]]), alpha)\n",
    "            forecast_values.append(fc)\n",
    "            forecast_intervals_lower.append(conf[0])\n",
    "            forecast_intervals_upper.append(conf[1])\n",
    "\n",
    "            # Updates the existing model with a small number of MLE steps\n",
    "            model.update(new_ob, np.array([exog_y_test[ind]]))\n",
    "            \n",
    "\n",
    "        forecast_intervals_lower = np.array(forecast_intervals_lower)\n",
    "        forecast_intervals_upper = np.array(forecast_intervals_upper)\n",
    "\n",
    "        ace = regression_ace(test_y, forecast_intervals_lower, forecast_intervals_upper, alpha)\n",
    "        mean_coverage = regression_mean_coverage(test_y, forecast_intervals_lower, forecast_intervals_upper)\n",
    "        average_width = regression_sharpness(forecast_intervals_lower, forecast_intervals_upper)\n",
    "        direction_accuracy_value = direction_accuracy(test_y, np.array(forecast_values).flatten())\n",
    "\n",
    "        print('The average coverage error is: '+str(ace))\n",
    "        print('The mean coverage: '+str(mean_coverage))\n",
    "        print('The PI average width: '+str(average_width))\n",
    "        print('The directional accuracy value is: '+str(direction_accuracy_value))\n",
    "\n",
    "        # Create a list with the values\n",
    "        cp_metric_data = [['ace', ace], ['mean_coverage', mean_coverage], ['average_width', average_width], ['direction_accuracy', direction_accuracy]]\n",
    "\n",
    "        # Specify the CSV file name\n",
    "        metrics_csv_file_name = folder_name+'\\\\arima_confidence_metrics_alp_'+str(int((1-alpha)*100))+'.csv'\n",
    "\n",
    "        # Write to the CSV file\n",
    "        with open(metrics_csv_file_name, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            # Write the header\n",
    "            writer.writerow(['Metric', 'Value'])\n",
    "            # Write the data\n",
    "            writer.writerows(cp_metric_data)\n",
    "\n",
    "        print(f\"Metrics saved to {metrics_csv_file_name}\")\n",
    "\n",
    "        # Create a dictionary with the arrays\n",
    "        actual_pred_data = {\n",
    "            'y_true': test_y,\n",
    "            'y_pred_from_arima': np.array(forecast_values).flatten(),\n",
    "            'y_lower': forecast_intervals_lower,\n",
    "            'y_upper': forecast_intervals_upper\n",
    "        }\n",
    "\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame(actual_pred_data)\n",
    "        \n",
    "        val_df = df[:760]\n",
    "        \n",
    "        test_df = df[760:]\n",
    "\n",
    "        # Specify the CSV file name\n",
    "        val_preds_actual_csv_file_name = folder_name+'\\\\val_arima_y_true_and_pred_alp_'+str(int((1-alpha)*100))+'.csv'\n",
    "        test_preds_actual_csv_file_name = folder_name+'\\\\test_arima_y_true_and_pred_alp_'+str(int((1-alpha)*100))+'.csv'\n",
    "        \n",
    "        # Write to the CSV file\n",
    "        val_df.to_csv(val_preds_actual_csv_file_name, index=False)\n",
    "        test_df.to_csv(test_preds_actual_csv_file_name, index=False)\n",
    "\n",
    "        #print(f\"Data saved to {preds_actual_csv_file_name}\")\n",
    "\n",
    "        ace_list.append(ace)\n",
    "        mean_coverage_list.append(mean_coverage)\n",
    "        average_width_list.append(average_width)\n",
    "        direction_accuracy_value_list.append(direction_accuracy_value)\n",
    "\n",
    "    # Create a new figure and axis (left y-axis)\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # Plot Mean Coverage on the left y-axis\n",
    "    ax1.plot(alphas, mean_coverage_list, label='Mean Coverage', marker='s', color='b')\n",
    "    ax1.set_xlabel('Alpha')\n",
    "    ax1.set_ylabel('Coverage', color='black')  # Generalized y-axis label\n",
    "    ax1.tick_params('y', colors='black')\n",
    "\n",
    "    # Plot 'Actual Confidence' as a dotted black line\n",
    "    ax1.plot(alphas, confidence, label='Actual Confidence', linestyle='--', color='black', marker='o', alpha=0.3)\n",
    "\n",
    "    # Create a second y-axis (right y-axis)\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # Plot Average Width on the right y-axis\n",
    "    ax2.plot(alphas, average_width_list, label='Average Width', marker='^', color='r')\n",
    "    ax2.set_ylabel('Average Width', color='r')\n",
    "    ax2.tick_params('y', colors='r')\n",
    "\n",
    "    # Set the font color for both y-axes to black\n",
    "    ax1.yaxis.label.set_color('black')\n",
    "    ax2.yaxis.label.set_color('black')\n",
    "\n",
    "    # Set the tick colors to black\n",
    "    ax1.tick_params(axis='y', colors='black')\n",
    "    ax2.tick_params(axis='y', colors='black')\n",
    "\n",
    "    # Add legends\n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "\n",
    "    # Title\n",
    "    plt.title('Confidence Interval Metric vs. Alpha for ARIMA Model')\n",
    "\n",
    "    # Save the plot as an image file\n",
    "    plt.savefig(folder_name+'\\\\val_arima_metrics_vs_alpha.png')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Combine lists into a list of tuples\n",
    "    metric_data = list(zip(ace_list, mean_coverage_list, average_width_list, direction_accuracy_value_list))\n",
    "\n",
    "    # Specify the CSV file name\n",
    "    csv_file_name = folder_name+'\\\\arima_multiple_alpha_metrics_data.csv'\n",
    "\n",
    "    # Write to the CSV file\n",
    "    with open(csv_file_name, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write the header\n",
    "        writer.writerow(['ACE', 'Mean Coverage', 'Average Width', 'Direction Accuracy'])\n",
    "        # Write the data\n",
    "        writer.writerows(metric_data)\n",
    "\n",
    "    print(f\"Metrics saved to {csv_file_name}\")\n",
    "    \n",
    "# Open a CSV file to save the order\n",
    "with open('.\\\\arimamodel_val_test_past_20\\\\arima_orders_'+target+'.csv', 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    \n",
    "    # Write the header\n",
    "    csvwriter.writerow(['target_alpha', 'order'])\n",
    "    \n",
    "    # Write the data\n",
    "    for string, tuple_value in zip(model_alpha, orders):\n",
    "        csvwriter.writerow([string, tuple_value])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
