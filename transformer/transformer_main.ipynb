{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396cecaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d892cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing the required libraries\n",
    "!pip install -r \"/content/drive/MyDrive/Masters in AI: Thesis/References/Time-series papers that were read and implemented/Nonstationary-Transfomers/Nonstationary_Transformers-main/Nonstationary_Transformers-main/requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a1b990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the non-stationary transformer model for 96, 192, 336 and 720-ahead predictions\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "def download_data(model_name):\n",
    "\n",
    "  pred_lens = [96, 192, 336, 720]\n",
    "\n",
    "  for pred_len in pred_lens:\n",
    "\n",
    "    # Create a folder\n",
    "    folder_name = model_name + '_'+str(pred_len)\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    files_to_download = []\n",
    "\n",
    "    for i in range(1):\n",
    "      files_to_download.append(f'metrics_run_{i}_{model_name}_{pred_len}.csv')\n",
    "      files_to_download.append(f'preds_run_{i}_{model_name}_{pred_len}.csv')\n",
    "      files_to_download.append(f'trues_run_{i}_{model_name}_{pred_len}.csv')\n",
    "\n",
    "    files_to_download.append(f'mean_std_metrics_{model_name}_{pred_len}.csv')\n",
    "\n",
    "    # Move files to the folder\n",
    "    for file_name in files_to_download:\n",
    "        shutil.move(file_name, os.path.join(folder_name, file_name))\n",
    "\n",
    "    # Zip the folder\n",
    "    shutil.make_archive(folder_name, 'zip', folder_name)\n",
    "\n",
    "    # Download the zip file\n",
    "    files.download(f'{folder_name}.zip')\n",
    "    \n",
    "bash_command96 = f'\"/content/drive/MyDrive/masters back up/Nonstationary-Transfomers/Nonstationary_Transformers-main/Nonstationary_Transformers-main/scripts/Exchange_script/Replication/ns_Transformer96.sh\"'\n",
    "bash_command192 = f'\"/content/drive/MyDrive/masters back up/Nonstationary-Transfomers/Nonstationary_Transformers-main/Nonstationary_Transformers-main/scripts/Exchange_script/Replication/ns_Transformer192.sh\"'\n",
    "bash_command336 = f'\"/content/drive/MyDrive/masters back up/Nonstationary-Transfomers/Nonstationary_Transformers-main/Nonstationary_Transformers-main/scripts/Exchange_script/Replication/ns_Transformer336.sh\"'\n",
    "bash_command720 = f'\"/content/drive/MyDrive/masters back up/Nonstationary-Transfomers/Nonstationary_Transformers-main/Nonstationary_Transformers-main/scripts/Exchange_script/Replication/ns_Transformer720.sh\"'\n",
    "\n",
    "!bash {bash_command96}\n",
    "!bash {bash_command192}\n",
    "!bash {bash_command336}\n",
    "!bash {bash_command720}\n",
    "\n",
    "download_data('ns_Transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdc3e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the non-stationary transformer model for 1-step ahead predictions\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "def download_data(model_name):\n",
    "\n",
    "  pred_len = 1\n",
    "\n",
    "  targets = ['0', '1', '2', '3', '4', '5', '6', 'OT']\n",
    "\n",
    "  for target in targets:\n",
    "\n",
    "    # Create a folder\n",
    "    folder_name = model_name + '_'+str(pred_len)\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    files_to_download = []\n",
    "\n",
    "    for i in range(1):\n",
    "      files_to_download.append(f'metrics_run_{i}_{model_name}_{pred_len}_{target}.csv')\n",
    "      files_to_download.append(f'preds_run_{i}_{model_name}_{pred_len}_{target}.csv')\n",
    "      files_to_download.append(f'trues_run_{i}_{model_name}_{pred_len}_{target}.csv')\n",
    "\n",
    "    #files_to_download.append(f'mean_std_metrics_{model_name}_{pred_len}_{target}.csv')\n",
    "\n",
    "    # Move files to the folder\n",
    "    for file_name in files_to_download:\n",
    "        shutil.move(file_name, os.path.join(folder_name, file_name))\n",
    "\n",
    "    # Zip the folder\n",
    "    shutil.make_archive(folder_name, 'zip', folder_name)\n",
    "\n",
    "    # Download the zip file\n",
    "    files.download(f'{folder_name}.zip')\n",
    "    \n",
    "bash_command1 = f'\"/content/drive/MyDrive/masters back up/Nonstationary-Transfomers/Nonstationary_Transformers-main/Nonstationary_Transformers-main/scripts/Exchange_script/Replication/ns_Transformer1.sh\"'\n",
    "\n",
    "!bash {bash_command1}\n",
    "\n",
    "download_data('ns_Transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c0279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the transformer model with the Monte Carlo Dropout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import shutilimport numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import files\n",
    "import csv\n",
    "import shutil\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def RSE(pred, true):\n",
    "    return np.sqrt(np.sum((true - pred) ** 2)) / np.sqrt(np.sum((true - true.mean()) ** 2))\n",
    "\n",
    "\n",
    "def CORR(pred, true):\n",
    "    u = ((true - true.mean(0)) * (pred - pred.mean(0))).sum(0)\n",
    "    d = np.sqrt(((true - true.mean(0)) ** 2 * (pred - pred.mean(0)) ** 2).sum(0))\n",
    "    return (u / d).mean(-1)\n",
    "\n",
    "\n",
    "def MAE(pred, true):\n",
    "    return np.mean(np.abs(pred - true))\n",
    "\n",
    "\n",
    "def MSE(pred, true):\n",
    "    return np.mean((pred - true) ** 2)\n",
    "\n",
    "\n",
    "def RMSE(pred, true):\n",
    "    return np.sqrt(MSE(pred, true))\n",
    "\n",
    "\n",
    "def MAPE(pred, true):\n",
    "    return np.mean(np.abs((pred - true) / true))\n",
    "\n",
    "\n",
    "def MSPE(pred, true):\n",
    "    return np.mean(np.square((pred - true) / true))\n",
    "\n",
    "\n",
    "def metric(pred, true):\n",
    "    mae = MAE(pred, true)\n",
    "    mse = MSE(pred, true)\n",
    "    rmse = RMSE(pred, true)\n",
    "    mape = MAPE(pred, true)\n",
    "    mspe = MSPE(pred, true)\n",
    "\n",
    "    return mae, mse, rmse, mape, mspe\n",
    "\n",
    "windows = [1]\n",
    "\n",
    "alphas = [0.01, 0.05, 0.1, 0.15]\n",
    "\n",
    "output_file_names = list()\n",
    "\n",
    "for window in windows:\n",
    "\n",
    "  output_file_name = \"output_mc_\" + str(window)\n",
    "\n",
    "  !rm -rf \"$output_file_name\"\n",
    "\n",
    "  !mkdir \"$output_file_name\"\n",
    "\n",
    "  \n",
    "  bash_command = f'\"/content/drive/MyDrive/masters back up/Nonstationary-Transfomers/Nonstationary_Transformers-main/Nonstationary_Transformers-main/scripts/Exchange_script/ns_Transformer_mc_{window}.sh\"'\n",
    "\n",
    "  !bash {bash_command}\n",
    "\n",
    "  pred_list = list()\n",
    "\n",
    "  \n",
    "  base_path = \"/content/results/Exchange_96_5_ns_Transformer_custom_ftMS_sl96_ll48_pl\"+str(window)+\"_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_h16_l2_0/\"\n",
    "  new_path = output_file_name + \"/\"\n",
    "  for i in range(10):\n",
    "      file_path = f\"{base_path}pred_{i}.npy\"\n",
    "      pred = np.load(file_path)\n",
    "      #files.download(file_path)\n",
    "      shutil.copy(file_path, new_path)\n",
    "      pred_list.append(pred)\n",
    "\n",
    "  pred_arrays = np.array(pred_list)\n",
    "\n",
    "  array_list = [arr for arr in pred_arrays] # removed [:,-1,0]\n",
    "\n",
    "  df = pd.DataFrame(array_list).T  # Transpose the DataFrame to have each array as a column\n",
    "\n",
    "  df.to_csv('mc_raw_output.csv', index=False)\n",
    "  shutil.move('mc_raw_output.csv', new_path)\n",
    "\n",
    "  # Calculate minimum, maximum, and mean along axis=1 (equivalent indexes)\n",
    "  min_values = df.min(axis=1)\n",
    "  max_values = df.max(axis=1)\n",
    "  mean_values = df.mean(axis=1)\n",
    "\n",
    "  # Convert the results back to arrays if needed\n",
    "  min_array = np.array(min_values).reshape(-1, 1)\n",
    "  max_array = np.array(max_values).reshape(-1, 1)\n",
    "  mean_array = np.array(mean_values).reshape(-1, 1)\n",
    "\n",
    "  # Create a DataFrame with named columns\n",
    "  min_max_mean = {\n",
    "      'min': min_array,\n",
    "      'max': max_array,\n",
    "      'mean': mean_array\n",
    "  }\n",
    "\n",
    "  # Flatten the arrays\n",
    "  for key, value in min_max_mean.items():\n",
    "      min_max_mean[key] = value.flatten()\n",
    "\n",
    "  df = pd.DataFrame(min_max_mean)\n",
    "\n",
    "  # Save the DataFrame to a CSV file\n",
    "  df.to_csv('min_max_mean.csv', index=False)\n",
    "  shutil.move('min_max_mean.csv', new_path)\n",
    "\n",
    "  #>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> calculating alpha\n",
    "\n",
    "  # Define a function to calculate lower, upper, and mean for a given alpha for each row\n",
    "  def calculate_confidence_intervals_for_row(row, alpha):\n",
    "      mean = np.mean(row)\n",
    "      std_dev = np.std(row)\n",
    "      n = len(row)\n",
    "      sem = std_dev / np.sqrt(n)\n",
    "      critical_value = stats.norm.ppf(1 - alpha / 2)  # For two-tailed confidence interval\n",
    "      margin_of_error = critical_value * sem\n",
    "      lower_bound = mean - margin_of_error\n",
    "      upper_bound = mean + margin_of_error\n",
    "      return lower_bound, upper_bound, mean\n",
    "\n",
    "  # Loop over different confidence levels (alphas)\n",
    "  for alpha in alphas:\n",
    "      # Calculate confidence intervals for each alpha for each row\n",
    "      confidence_intervals = df.apply(lambda row: calculate_confidence_intervals_for_row(row, alpha), axis=1, result_type='expand')\n",
    "      confidence_intervals.columns = ['lower', 'upper', 'mean']\n",
    "\n",
    "      # Save DataFrame to a CSV file\n",
    "      filename = f\"min_max_mean_alpha_{alpha}.csv\"\n",
    "      confidence_intervals.to_csv(filename, index=False)\n",
    "      shutil.move(filename, new_path)\n",
    "\n",
    "  \n",
    "  # Create the plot\n",
    "  plt.figure(figsize=(10, 6))\n",
    "\n",
    "  true_0 = np.load(f\"{base_path}true_0.npy\")\n",
    "  #files.download(f\"{base_path}true_0.npy\")\n",
    "  shutil.move(f\"{base_path}true_0.npy\", new_path)\n",
    "\n",
    "  x_test = np.load(f\"{base_path}x_test.npy\")\n",
    "  shutil.move(f\"{base_path}x_test.npy\", new_path)\n",
    "\n",
    "  checkpoint_base_path = \"/content/checkpoints/Exchange_96_5_ns_Transformer_custom_ftMS_sl96_ll48_pl1_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_h16_l2_0/\"\n",
    "  shutil.copy(f\"{checkpoint_base_path}checkpoint.pth\", new_path)\n",
    "\n",
    "  true_last = true_0#[:, -1, 0]\n",
    "\n",
    "  # Plot the mean values as a line\n",
    "  plt.plot(true_last[:100], label='Actual', color='blue')\n",
    "  plt.plot(mean_array[:100], label='Mean', color='black')\n",
    "\n",
    "  # Fill the area between the minimum and maximum values to represent confidence bands\n",
    "  plt.fill_between(range(len(min_array[:100])), min_array[:100].squeeze(), max_array[:100].squeeze(), alpha=0.3, color='gray', label='Confidence Band')\n",
    "\n",
    "  # Customize the plot\n",
    "  if window == 1:\n",
    "    plt.title(f\"MC Dropout with Model Forecasting {window} Day Ahead\")\n",
    "  else:\n",
    "    plt.title(f\"MC Dropout with Model Forecasting {window} Days Ahead\")\n",
    "  plt.xlabel('Index')\n",
    "  plt.ylabel('Values')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\n",
    "\n",
    "  plt.savefig(\"plot.png\")\n",
    "  #files.download(\"plot.png\")\n",
    "  shutil.move(\"plot.png\", new_path)\n",
    "\n",
    "  # Show the plot\n",
    "  plt.show()\n",
    "\n",
    "  metrics = metric(mean_array, true_last)\n",
    "\n",
    "\n",
    "  # Specify the CSV file path\n",
    "  csv_file = \"metrics.csv\"  # You can choose the desired file name\n",
    "\n",
    "\n",
    "  # Create a header\n",
    "  header = [\"mae\", \"mse\", \"rmse\", \"mape\", \"mspe\"]\n",
    "\n",
    "  # Write the data to the CSV file\n",
    "  with open(csv_file, 'w', newline='') as file:\n",
    "      writer = csv.writer(file)\n",
    "\n",
    "      # Write the headers\n",
    "      writer.writerow(header)\n",
    "\n",
    "      # Write the data as a single row\n",
    "      writer.writerow(metrics)\n",
    "\n",
    "  #files.download(\"metrics.csv\")\n",
    "  shutil.move(\"metrics.csv\", new_path)\n",
    "\n",
    "  !zip -r \"$output_file_name\" \"$output_file_name\"\n",
    "\n",
    "  output_file_names.append(output_file_name)\n",
    "\n",
    "  !rm -rf checkpoints\n",
    "  !rm -rf results\n",
    "  !rm -rf test_results\n",
    "  !rm -rf metrics.csv\n",
    "  !rm -rf plot.png\n",
    "  !rm -rf results.txt\n",
    "  !rm -rf result.txt\n",
    "  !rm -rf min_max_mean.csv\n",
    "\n",
    "for output_file_name in output_file_names:\n",
    "  files.download(output_file_name + \".zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3182e909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer with the EnbPI uncertainty\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "!pip install puncc\n",
    "\n",
    "bash_command = f'\"/content/drive/MyDrive/masters back up/Nonstationary-Transfomers/Nonstationary_Transformers-main/Nonstationary_Transformers-main/scripts/Exchange_script/ns_Transformer_EnbPI.sh\"'\n",
    "\n",
    "!bash {bash_command}\n",
    "\n",
    "# Downloading the models and residuals\n",
    "\n",
    "alphas = [0.01, 0.05, 0.1, 0.15]\n",
    "ss = [100, 50, 25, 20, 10, 5]\n",
    "\n",
    "for alpha in alphas:\n",
    "  for s in ss:\n",
    "\n",
    "    # Create a folder\n",
    "    folder_name = 'transformer_confidence_run_data'+str(int((1-alpha)*100))+'_s_'+str(s)\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    files_to_download = ['plot_with_CP_PUNCC_alp_'+str(int((1-alpha)*100))+'_s_'+str(s)+'.png', 'BootstrappedPredictionsvsActual.png','transformer_confidence_metrics_alp_'+str(int((1-alpha)*100))+'_s_'+str(s)+'.csv','y_true_and_pred_alp_'+str(int((1-alpha)*100))+'_s_'+str(s)+'.csv']\n",
    "\n",
    "    # Move files to the folder\n",
    "    for file_name in files_to_download:\n",
    "        shutil.move(file_name, os.path.join(folder_name, file_name))\n",
    "\n",
    "    # Zip the folder\n",
    "    shutil.make_archive(folder_name, 'zip', folder_name)\n",
    "\n",
    "    # Download the zip file\n",
    "    files.download(f'{folder_name}.zip')\n",
    "\n",
    "alpha = 0.05\n",
    "s = 100\n",
    "\n",
    "# Create a folder\n",
    "folder_name = 'transformer_confidence_run_model_data'\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "files_to_download = []\n",
    "\n",
    "# Download files named 0.pth, 1.pth... up until 29.pth\n",
    "for i in range(30):\n",
    "    files_to_download.append(f'{i}.pth')\n",
    "\n",
    "# Download files whose name begins with 'plot'\n",
    "files_to_download += [file_name for file_name in os.listdir() if file_name.startswith('plot')]\n",
    "\n",
    "# Download files whose name is 'result.txt'\n",
    "files_to_download.append('result.txt')\n",
    "\n",
    "# Move files to the folder\n",
    "for file_name in files_to_download:\n",
    "    shutil.move(file_name, os.path.join(folder_name, file_name))\n",
    "\n",
    "# Zip the folder\n",
    "shutil.make_archive(folder_name, 'zip', folder_name)\n",
    "\n",
    "# Download the zip file\n",
    "files.download(f'{folder_name}.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a016970",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install arch\n",
    "!pip install puncc\n",
    "\n",
    "bash_command = f'\"/content/drive/MyDrive/masters back up/Nonstationary-Transfomers/Nonstationary_Transformers-main/Nonstationary_Transformers-main/scripts/Exchange_script/ns_Transformer_GARCH.sh\"'\n",
    "\n",
    "!bash {bash_command}\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "alphas = [0.01, 0.05, 0.1, 0.15]\n",
    "targets=['0', '1', '2', '3', '4', '5', '6', 'OT']\n",
    "lags = str(8)\n",
    "\n",
    "for target in targets:\n",
    "\n",
    "  for alpha in alphas:\n",
    "\n",
    "    # Create a folder\n",
    "    folder_name = 'garch_transformer_confidence_run_data_alpha_'+str(alpha)+'_target_' + target +'_lags_' + lags\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    files_to_download = ['plot_with_CP_GARCH_alpha_'+str((1-alpha)*100)+'_'+target+'.png', 'garch_transformer_confidence_metrics_alp_'+str(int((1-alpha)*100))+'_'+target+'.csv','garch_transforemer_y_true_and_pred_alp_'+str(int((1-alpha)*100))+'_'+target+'.csv']\n",
    "\n",
    "    # Move files to the folder\n",
    "    for file_name in files_to_download:\n",
    "        shutil.move(file_name, os.path.join(folder_name, file_name))\n",
    "\n",
    "    # Zip the folder\n",
    "    shutil.make_archive(folder_name, 'zip', folder_name)\n",
    "\n",
    "    # Download the zip file\n",
    "    files.download(f'{folder_name}.zip')\n",
    "\n",
    "  for alpha in alphas:\n",
    "\n",
    "    # Create a folder\n",
    "    folder_name = 'val_garch_transformer_confidence_run_data_alpha_'+str(alpha)+'_target_' + target +'_lags_' + lags\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    files_to_download = ['val_plot_with_CP_GARCH_alpha_'+str((1-alpha)*100)+'_'+target+'.png', 'val_garch_transformer_confidence_metrics_alp_'+str(int((1-alpha)*100))+'_'+target+'.csv','val_garch_transforemer_y_true_and_pred_alp_'+str(int((1-alpha)*100))+'_'+target+'.csv']\n",
    "\n",
    "    # Move files to the folder\n",
    "    for file_name in files_to_download:\n",
    "        shutil.move(file_name, os.path.join(folder_name, file_name))\n",
    "\n",
    "    # Zip the folder\n",
    "    shutil.make_archive(folder_name, 'zip', folder_name)\n",
    "\n",
    "    # Download the zip file\n",
    "    files.download(f'{folder_name}.zip')\n",
    "    \n",
    "\n",
    "\n",
    "for target in targets:\n",
    "\n",
    "  for alpha in alphas:\n",
    "\n",
    "    # Create a folder\n",
    "    folder_name = 'garch_transformer_confidence_run_data_alpha_'+str(alpha)+'_target_' + target +'_lags_' + lags\n",
    "\n",
    "    # Download the zip file\n",
    "    files.download(f'{folder_name}.zip')\n",
    "\n",
    "  for alpha in alphas:\n",
    "\n",
    "    # Create a folder\n",
    "    folder_name = 'val_garch_transformer_confidence_run_data_alpha_'+str(alpha)+'_target_' + target +'_lags_' + lags\n",
    "    # Download the zip file\n",
    "    files.download(f'{folder_name}.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
